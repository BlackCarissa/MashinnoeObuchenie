{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Переобучение нейронных сетей и борьба с ним\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import time\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "def args_and_kwargs(*args, **kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        layer_info = {\"type\": layer_name.strip()}\n",
    "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
    "        \n",
    "        param_dict = {}\n",
    "        if len(params):\n",
    "            args, kwargs = eval(params_template)\n",
    "            if len(args) or len(kwargs):\n",
    "                param_dict[\"args\"] = args\n",
    "                for name, value in kwargs.items():\n",
    "                    param_dict[name] = value\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
    "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
    "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 6')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): Linear(in_features=2028, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = nn.Sequential(\n",
    "    #nn.Linear(1*784,512),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Linear(512,10)\n",
    "    nn.Conv2d(1,10,3,padding=1), # 1 канал (оттенки серого), 10 фильтров, 3x3 размер фильтра, padding по краям = 1\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(10,3,3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2028,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10)\n",
    "\n",
    ")\n",
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): Linear(in_features=2028, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, 13.539s. loss: 0.0000\n",
      "\t training loss: 0.371448\n",
      "\t validation loss: 0.338588\n",
      "\t val accuracy: 0.937500\n",
      "epoch 2/10, 13.402s. loss: 0.0000\n",
      "\t training loss: 0.403184\n",
      "\t validation loss: 0.288866\n",
      "\t val accuracy: 0.875000\n",
      "epoch 3/10, 12.544s. loss: 0.0000\n",
      "\t training loss: 0.326229\n",
      "\t validation loss: 0.293220\n",
      "\t val accuracy: 0.937500\n",
      "epoch 4/10, 13.135s. loss: 0.0000\n",
      "\t training loss: 0.282411\n",
      "\t validation loss: 0.167388\n",
      "\t val accuracy: 0.937500\n",
      "epoch 5/10, 14.072s. loss: 0.0000\n",
      "\t training loss: 0.195066\n",
      "\t validation loss: 0.295056\n",
      "\t val accuracy: 0.875000\n",
      "epoch 6/10, 12.189s. loss: 0.0000\n",
      "\t training loss: 0.252309\n",
      "\t validation loss: 0.241912\n",
      "\t val accuracy: 0.875000\n",
      "epoch 7/10, 13.853s. loss: 0.0000\n",
      "\t training loss: 0.198014\n",
      "\t validation loss: 0.198303\n",
      "\t val accuracy: 0.812500\n",
      "epoch 8/10, 13.499s. loss: 0.0000\n",
      "\t training loss: 0.094192\n",
      "\t validation loss: 0.047987\n",
      "\t val accuracy: 1.000000\n",
      "epoch 9/10, 13.291s. loss: 0.0000\n",
      "\t training loss: 0.022347\n",
      "\t validation loss: 0.137293\n",
      "\t val accuracy: 0.937500\n",
      "epoch 10/10, 12.775s. loss: 0.0000\n",
      "\t training loss: 0.008882\n",
      "\t validation loss: 0.033541\n",
      "\t val accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "default_dtype = torch.float32\n",
    "def train_model(model,train_loader,val_loader,loss_fn,optimizer,epochs: int, device=device):\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for X,Y in train_loader:\n",
    "            X,Y = X.to(device), Y.to(device)\n",
    "            output=model(X)\n",
    "            loss=loss_fn(output, Y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            for X,Y in val_loader:\n",
    "                X,Y = X.to(device), Y.to(device)\n",
    "                output=model(X)\n",
    "                loss=loss_fn(output, Y)\n",
    "                losses_test.append(loss.item())\n",
    "                y_pred = output.max(-1)[1]\n",
    "                acc.append((y_pred==Y).to(default_dtype).mean().item())\n",
    "        print(f'epoch {epoch+1}/{epochs}, {time.time()-start_time:.3f}s.')\n",
    "        print(f'\\t training loss: {losses_train[-1]:.6f}')\n",
    "        print(f'\\t validation loss: {losses_test[-1]:.6f}')\n",
    "        print(f'\\t val accuracy: {acc[-1]:.6f}')\n",
    "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=1e-3)\n",
    "epochs=10\n",
    "train_model(model_task_1, train_data_loader,test_data_loader,nn.CrossEntropyLoss(),optimizer,epochs,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.98022\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9028\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №2: Переобучение (Initiation)\n",
    "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
    "\n",
    "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
    "\n",
    "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче. \n",
    "\n",
    "Не используйте `Dropout` и `BatchNorm` в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=2028, out_features=600, bias=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=600, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating model instance\n",
    "model_task_2 = nn.Sequential(\n",
    "    nn.Conv2d(1,10,3,padding=1), # 1 канал (оттенки серого), 10 фильтров, 3x3 размер фильтра, padding по краям = 1\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(10,3,3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2028,600,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(600,128,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10)\n",
    "\n",
    ")\n",
    "default_dtype = torch.float32\n",
    "model_task_2.to(device,default_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, 13.324s.\n",
      "\t training loss: 0.334837\n",
      "\t validation loss: 0.202931\n",
      "\t val accuracy: 0.937500\n",
      "epoch 2/10, 12.565s.\n",
      "\t training loss: 0.297732\n",
      "\t validation loss: 0.209387\n",
      "\t val accuracy: 0.937500\n",
      "epoch 3/10, 12.524s.\n",
      "\t training loss: 0.434069\n",
      "\t validation loss: 0.195482\n",
      "\t val accuracy: 0.937500\n",
      "epoch 4/10, 13.869s.\n",
      "\t training loss: 0.095665\n",
      "\t validation loss: 0.225577\n",
      "\t val accuracy: 0.875000\n",
      "epoch 5/10, 13.612s.\n",
      "\t training loss: 0.359238\n",
      "\t validation loss: 0.104408\n",
      "\t val accuracy: 1.000000\n",
      "epoch 6/10, 13.595s.\n",
      "\t training loss: 0.199961\n",
      "\t validation loss: 0.089457\n",
      "\t val accuracy: 0.937500\n",
      "epoch 7/10, 13.581s.\n",
      "\t training loss: 0.020645\n",
      "\t validation loss: 0.092464\n",
      "\t val accuracy: 0.937500\n",
      "epoch 8/10, 13.980s.\n",
      "\t training loss: 0.136786\n",
      "\t validation loss: 0.245658\n",
      "\t val accuracy: 0.937500\n",
      "epoch 9/10, 13.460s.\n",
      "\t training loss: 0.058918\n",
      "\t validation loss: 0.321387\n",
      "\t val accuracy: 0.937500\n",
      "epoch 10/10, 12.939s.\n",
      "\t training loss: 0.036781\n",
      "\t validation loss: 0.034349\n",
      "\t val accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def train_model(model,train_loader,val_loader,loss_fn,optimizer,epochs: int, device=device):\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for X,Y in train_loader:\n",
    "            X,Y = X.to(device), Y.to(device)\n",
    "            output=model(X)\n",
    "            loss=loss_fn(output, Y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            for X,Y in val_loader:\n",
    "                X,Y = X.to(device), Y.to(device)\n",
    "                output=model(X)\n",
    "                loss=loss_fn(output, Y)\n",
    "                losses_test.append(loss.item())\n",
    "                y_pred = output.max(-1)[1]\n",
    "                acc.append((y_pred==Y).to(default_dtype).mean().item())\n",
    "        print(f'epoch {epoch+1}/{epochs}, {time.time()-start_time:.3f}s.')\n",
    "        print(f'\\t training loss: {losses_train[-1]:.6f}')\n",
    "        print(f'\\t validation loss: {losses_test[-1]:.6f}')\n",
    "        print(f'\\t val accuracy: {acc[-1]:.6f}')\n",
    "optimizer = torch.optim.Adam(model_task_2.parameters(), lr=1e-3)\n",
    "epochs=10\n",
    "train_model(model_task_2, train_data_loader,test_data_loader,nn.CrossEntropyLoss(),optimizer,epochs,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
    "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
    "    layers_task_2.append(layer_name)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.98832\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9055\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
    "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert (\n",
    "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
    "), \"Test accuracy should be at least 0.04 lower that train.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_tasks_1_and_2.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №3: Исправление модели (Return) \n",
    "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
    "\n",
    "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
    "\n",
    "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче. \n",
    "\n",
    "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    layers_task_2 is not None\n",
    "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.25, inplace=False)\n",
       "  (7): Flatten(start_dim=1, end_dim=-1)\n",
       "  (8): Linear(in_features=2028, out_features=600, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=600, out_features=128, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Dropout(p=0.25, inplace=False)\n",
       "  (13): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_3 = nn.Sequential(\n",
    "    nn.Conv2d(1,10,3,padding=1), # 1 канал (оттенки серого), 10 фильтров, 3x3 размер фильтра, padding по краям = 1\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(10,3,3),\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2028,600,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(600,128,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(128,10)\n",
    "\n",
    ")\n",
    "model_task_3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/3, 25.269s.\n",
      "\t training loss: 0.295870\n",
      "\t validation loss: 0.283965\n",
      "\t val accuracy: 0.937500\n",
      "\t tr/tst diff: (tensor(0.0097), tensor(0.8527), tensor(0.8430))\n",
      "epoch 2/3, 25.215s.\n",
      "\t training loss: 0.530982\n",
      "\t validation loss: 0.241767\n",
      "\t val accuracy: 0.937500\n",
      "\t tr/tst diff: (tensor(0.0079), tensor(0.8746), tensor(0.8667))\n",
      "epoch 3/3, 45.504s.\n",
      "\t training loss: 0.329566\n",
      "\t validation loss: 0.234099\n",
      "\t val accuracy: 0.937500\n",
      "\t tr/tst diff: (tensor(0.0110), tensor(0.8878), tensor(0.8768))\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def train_model(model,train_loader,val_loader,loss_fn,optimizer,epochs: int, device=device):\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for X,Y in train_loader:\n",
    "            X,Y = X.to(device), Y.to(device)\n",
    "            output=model(X)\n",
    "            loss=loss_fn(output, Y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            for X,Y in val_loader:\n",
    "                X,Y = X.to(device), Y.to(device)\n",
    "                output=model(X)\n",
    "                loss=loss_fn(output, Y)\n",
    "                losses_test.append(loss.item())\n",
    "                y_pred = output.max(-1)[1]\n",
    "                acc.append((y_pred==Y).to(default_dtype).mean().item())\n",
    "        train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "        test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "        print(f'epoch {epoch+1}/{epochs}, {time.time()-start_time:.3f}s.')\n",
    "        print(f'\\t training loss: {losses_train[-1]:.6f}')\n",
    "        print(f'\\t validation loss: {losses_test[-1]:.6f}')\n",
    "        print(f'\\t val accuracy: {acc[-1]:.6f}')\n",
    "        print(f'\\t tr/tst diff: {train_acc_task_3-test_acc_task_3,train_acc_task_3,test_acc_task_3}')\n",
    "        \n",
    "optimizer = torch.optim.SGD(model_task_3.parameters(), lr=0.008)\n",
    "epochs=3\n",
    "train_model(model_task_3, train_data_loader,test_data_loader,nn.CrossEntropyLoss(),optimizer,epochs,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_3 = []\n",
    "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    layers_task_3.append(layer_name)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for model_3_layer in layers_task_3:\n",
    "    model_2_layer = layers_task_2[idx]\n",
    "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
    "        assert (\n",
    "            model_3_layer == model_2_layer\n",
    "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
    "        idx += 1\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.88775\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8768\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
    "assert (\n",
    "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
    "), \"Test accuracy should not be lower that train more than by 0.015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_final.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_final.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai8JL3tgSq_"
   },
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
    "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
    "* `submission_dict_final.json` в задачу Return.\n",
    "\n",
    "\n",
    "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
