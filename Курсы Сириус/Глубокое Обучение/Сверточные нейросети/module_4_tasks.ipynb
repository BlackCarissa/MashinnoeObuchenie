{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2d784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b8245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_compare(x, y):\n",
    "    if str(x) != str(y):\n",
    "        raise RuntimeError(f'Ожидаемое значение: {y}. Фактическое: {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef83271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(x, precision=2):\n",
    "    return [round(x, precision) for x in x.flatten().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb903f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list_m(m, precision=2):\n",
    "    res = []\n",
    "    \n",
    "    for l in m.tolist():\n",
    "        res.append([round(x, precision) for x in l])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8299078d",
   "metadata": {},
   "source": [
    "# Современные архитектуры свёрточных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed1aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Sequential, Conv2d, MaxPool2d\n",
    "from torch import cat\n",
    "\n",
    "def set_seed():\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    SEED = 0\n",
    "\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76faf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(Module):\n",
    "    def __init__(self, c_in, c_1, c_2, c_3):\n",
    "        # Необходимый для проверки корректности работы inception-блока код.\n",
    "        set_seed()\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Свёртка C1 размера 1x1.\n",
    "        self.c1 = Conv2d(c_in,c_1,1)\n",
    "        \n",
    "        # TODO: Свёртка C5 размера 1x1.\n",
    "        self.c5 = Conv2d(c_in,c_1,1)\n",
    "        # TODO: Свёртка C2 размера 3x3. Параметр padding = 1.\n",
    "        self.c2 = Conv2d(c_1,c_2,3,padding=1)\n",
    "        \n",
    "        # TODO: Свёртка C6 размера 1x1.\n",
    "        self.c6 = Conv2d(c_in,c_1,1)\n",
    "        # TODO: Свёртка C3 размера 5x5. Параметр padding = 2.\n",
    "        self.c3 = Conv2d(c_1,c_3,5,padding=2)\n",
    "        \n",
    "        # TODO: MaxPooling 2D MP1 размера 3x3. Параметры stride = 1, padding = 1.\n",
    "        self.mp1 = MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        # TODO: Свёртка C4 размера 1x1.\n",
    "        self.c4 = Conv2d(c_in,c_1,1)\n",
    "        \n",
    "        \n",
    "        # Полная ветка блока со свёрткой 3x3.\n",
    "        self.block_3_3 = Sequential(\n",
    "            self.c5,\n",
    "            self.c2,\n",
    "        )\n",
    "        \n",
    "        # Полная ветка блока со свёрткой 5x5.\n",
    "        self.block_5_5 = Sequential(\n",
    "            self.c6,\n",
    "            self.c3,\n",
    "        )\n",
    "        \n",
    "        # Полная ветка блока с MaxPooling 2D.\n",
    "        self.block_pool = Sequential(\n",
    "            self.mp1,\n",
    "            self.c4,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # В качестве результата работы inception-блок возвращает\n",
    "        # соединение по размерности каналов результатов работы внутренних\n",
    "        # свёрток и MaxPooling 2D.\n",
    "        return cat([\n",
    "            self.c1(x),\n",
    "            self.block_3_3(x),\n",
    "            self.block_5_5(x),\n",
    "            self.block_pool(x),\n",
    "        ], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b93f4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block_test():\n",
    "    example_1_x = torch.tensor([[[[0.28, 0.48], \n",
    "                                  [0.82, 1.0]]\n",
    "                                ]])\n",
    "    example_1_res = [-0.83, -0.83, -0.83, -0.83, -0.59, -0.48, -0.3, -0.2, 0.35, 0.69, 0.27, 0.58, -0.14, -0.15, -0.09, -0.05, 0.23, -0.1, -0.14, -0.33, -0.15, -0.15, -0.15, -0.15, 0.74, 0.74, 0.74, 0.74]\n",
    "    \n",
    "    inception_block_1 = InceptionBlock(1, 2, 1, 2)\n",
    "    custom_compare(to_list(inception_block_1(example_1_x)), example_1_res)\n",
    "    \n",
    "    \n",
    "    example_2_x = [0.26, 0.37, 0.18, 0.56, 0.94, 0.91, 0.62, 0.21, 0.2, 0.75, 0.75, 0.01, 0.79, 0.62, 0.33, 0.31]\n",
    "    example_2_x = torch.tensor(example_2_x).reshape(2, 2, 2, 2)\n",
    "    \n",
    "    example_2_res = [-0.23, -0.24, -0.35, -0.51, 0.09, 0.08, -0.02, -0.04, -0.17, -0.08, -0.15, -0.17, 0.63, 0.63, 0.63, 0.63, -0.28, -0.35, -0.46, -0.46, 0.1, 0.11, 0.01, -0.12, -0.2, -0.07, -0.14, -0.2, 0.49, 0.49, 0.49, 0.49]\n",
    "    \n",
    "    inception_block_2 = InceptionBlock(2, 1, 1, 1)\n",
    "    \n",
    "    custom_compare(to_list(inception_block_2(example_2_x)), example_2_res)\n",
    "    \n",
    "    print('Тесты прошли успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6ebfef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты прошли успешно!\n"
     ]
    }
   ],
   "source": [
    "inception_block_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db8083",
   "metadata": {},
   "source": [
    "# Датасет STL-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db179ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import pil_to_tensor, to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c48d813",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stl10_subset_X.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Загружаем подмножество изображений из датасета STL-10.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stl10_subset_X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstl10_subset_X.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загруажем метки для этих изображений.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m stl10_subset_y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstl10_subset_y.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\ilyav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\ilyav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\ilyav\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stl10_subset_X.pt'"
     ]
    }
   ],
   "source": [
    "# Загружаем подмножество изображений из датасета STL-10.\n",
    "stl10_subset_X = torch.load('stl10_subset_X.pt')\n",
    "# Загруажем метки для этих изображений.\n",
    "stl10_subset_y = [int(x) for x in torch.load('stl10_subset_y.pt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Названия классов из STL-10.\n",
    "# На позиции i в спсике находится название класса с меткой i в данных.\n",
    "stl10_classes = [\n",
    "    'airplane',\n",
    "    'bird',\n",
    "    'car',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'horse',\n",
    "    'monkey',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31fe33",
   "metadata": {},
   "source": [
    "## Примеры изображений из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2768c",
   "metadata": {
    "cellId": "r32v4e4xh3jpckce93cgfr"
   },
   "outputs": [],
   "source": [
    "num_obj = 6\n",
    "\n",
    "fig, ax = plt.subplots(1, num_obj, figsize=(30, 64))\n",
    "\n",
    "seen_classes = set()\n",
    "j = 0\n",
    "for img_tensor, cl in zip(stl10_subset_X, stl10_subset_y):\n",
    "    if cl not in seen_classes:\n",
    "        plt.subplot(1, num_obj, j + 1)\n",
    "        plt.imshow(to_pil_image(img_tensor))\n",
    "        plt.title(f\"Класс '{stl10_classes[cl]}'\")\n",
    "\n",
    "        seen_classes.add(cl)\n",
    "        j += 1\n",
    "        if j == num_obj:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f9c7e",
   "metadata": {},
   "source": [
    "# Аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0d1fd",
   "metadata": {
    "cellId": "gfnb1fbm1jnvmy0huwr8"
   },
   "outputs": [],
   "source": [
    "img, cl = to_pil_image(stl10_subset_X[0]), stl10_classes[stl10_subset_y[0]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 8))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Класс '{cl}'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a73556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Гарантированно отражает изображение вертикально.\n",
    "vertical_flip = transforms.RandomVerticalFlip(1.)\n",
    "\n",
    "# Гарантированно отражает изображение горизонтально.\n",
    "horizontal_flip = transforms.RandomHorizontalFlip(1.)\n",
    "\n",
    "# Гарантированно поворачивает изображение на 30 градусов по часовой стрелке.\n",
    "clockwise_rotation = transforms.RandomRotation((-30, -30))\n",
    "\n",
    "# Гарантированно поворачивает изображение на 30 градусов против часовой стрелки.\n",
    "counter_clockwise_rotation = transforms.RandomRotation((30, 30))\n",
    "\n",
    "# Уменьшает яркость.\n",
    "lower_brightness = transforms.ColorJitter(brightness=(0.3, 0.3))\n",
    "\n",
    "# Увеличивает яркость.\n",
    "increase_brightness = transforms.ColorJitter(brightness=(1.7, 1.7))\n",
    "\n",
    "# Уменьшает насыщенность.\n",
    "lower_saturation = transforms.ColorJitter(saturation=(0.3, 0.3))\n",
    "\n",
    "# Увеличивает насыщенность.\n",
    "increase_saturation = transforms.ColorJitter(saturation=(4., 4.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0294d",
   "metadata": {},
   "source": [
    "## Подбор аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_img = to_pil_image(torch.load('bird_transformed.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f3ba8",
   "metadata": {
    "cellId": "hg4759bvydf37cjlx22pm8"
   },
   "outputs": [],
   "source": [
    "# Необходимо подобрать аугментации изображения и указать\n",
    "# их в качестве элементов списка внутри Compose.\n",
    "transforms_func = transforms.Compose([\n",
    "    None\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(transforms_func(img))\n",
    "plt.title(f\"Получилось после аугментаций\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(needed_img)\n",
    "plt.title(\"Должно получиться\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c2f46",
   "metadata": {},
   "source": [
    "# Использование предобученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "weights = models.ResNet50_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для преобразования входных данных — transforms.\n",
    "model_transform = weights.transforms()\n",
    "\n",
    "# TODO: Необходимо собрать модель ResNet-50 из models.resnet50,\n",
    "#       подгрузив в неё веса из переменной weights.\n",
    "#       По аналогии с тем, как это было в лекции.\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7527324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Необходимо преобразовать с помощью\n",
    "#       model_transform значения из stl10_subset_X,\n",
    "#       используя model_transform как обычную функцию.\n",
    "#       Это нужно для того, чтобы привести изображения из STL-10\n",
    "#       к формату, в котором с ними работает ResNet-50,\n",
    "#       обученная на ImageNet.\n",
    "stl10_res_subset_X = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl10_res_subset_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39279a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание классов для изображений из STL-10 с помощью ResNet-50.\n",
    "with torch.no_grad():\n",
    "    pred = model(stl10_res_subset_X).max(-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92869a",
   "metadata": {},
   "source": [
    "## Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "    imagenet_classes = {}\n",
    "    \n",
    "    for x in f:\n",
    "        ind, cls = x.strip().split(';')\n",
    "        imagenet_classes[int(ind)] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ниже приведены 16 изображений из STL-10, для каждого из которых с помощью ResNet-50\n",
    "# был предсказан класс в соответствии с теми классами, которые есть в ImageNet.\n",
    "# У датасетов есть пересечение по классам, поэтому модель корректно\n",
    "# классифицирует часть изображений из STL-10.\n",
    "\n",
    "num_obj = 16\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(30, 32))\n",
    "\n",
    "seen_classes = set()\n",
    "j = 0\n",
    "for img_tensor, cl in zip(stl10_subset_X, pred):\n",
    "    if cl not in seen_classes:\n",
    "        plt.subplot(4, 4, j + 1)\n",
    "        plt.imshow(to_pil_image(img_tensor))\n",
    "        plt.title(f\"Класс '{imagenet_classes[int(cl)]}'\")\n",
    "\n",
    "        seen_classes.add(cl)\n",
    "        j += 1\n",
    "        if j == num_obj:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea1000",
   "metadata": {},
   "source": [
    "## Значение, которое нужно отправить в систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_list(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
