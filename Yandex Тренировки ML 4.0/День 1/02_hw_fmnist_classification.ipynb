{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "# Домашнее задание №1\n",
    "## Часть2: Классификация FashionMNIST\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/rads_ai\n",
    "\n",
    "В данном задании вам предстоит решить достаточно простую задачу классификации изображений с помощью сверточных нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import time\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:08<00:00, 3.01MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 57.4kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.68MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 16.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 9')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(5, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=2028, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Dropout(p=0.5, inplace=False)\n",
       "  (10): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating model instance\n",
    "model_task_1 = nn.Sequential(\n",
    "    nn.Conv2d(1,5,3,padding=1), # 1 канал (оттенки серого), 10 фильтров, 3x3 размер фильтра, padding по краям = 1\n",
    "    nn.BatchNorm2d(5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(5,3,3),\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2028,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128,10)\n",
    ")\n",
    "model_task_1.to(device)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(5, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=2028, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Dropout(p=0.5, inplace=False)\n",
       "  (10): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/6, 21.986s.\n",
      "\t training loss: 0.391540\n",
      "\t validation loss: 0.215969\n",
      "\t val accuracy: 0.875000\n",
      "\t tr/tst diff: (tensor(0.0109), tensor(0.8637), tensor(0.8528))\n",
      "epoch 2/6, 21.516s.\n",
      "\t training loss: 0.315096\n",
      "\t validation loss: 0.135767\n",
      "\t val accuracy: 1.000000\n",
      "\t tr/tst diff: (tensor(0.0109), tensor(0.8840), tensor(0.8731))\n",
      "epoch 3/6, 21.415s.\n",
      "\t training loss: 0.275656\n",
      "\t validation loss: 0.155212\n",
      "\t val accuracy: 0.937500\n",
      "\t tr/tst diff: (tensor(0.0118), tensor(0.8800), tensor(0.8682))\n",
      "epoch 4/6, 21.458s.\n",
      "\t training loss: 0.346702\n",
      "\t validation loss: 0.091566\n",
      "\t val accuracy: 1.000000\n",
      "\t tr/tst diff: (tensor(0.0190), tensor(0.9008), tensor(0.8818))\n",
      "epoch 5/6, 21.538s.\n",
      "\t training loss: 0.261612\n",
      "\t validation loss: 0.122003\n",
      "\t val accuracy: 1.000000\n",
      "\t tr/tst diff: (tensor(0.0167), tensor(0.9084), tensor(0.8917))\n",
      "epoch 6/6, 21.406s.\n",
      "\t training loss: 0.211746\n",
      "\t validation loss: 0.101402\n",
      "\t val accuracy: 1.000000\n",
      "\t tr/tst diff: (tensor(0.0192), tensor(0.9113), tensor(0.8921))\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def train_model(model,train_loader,val_loader,loss_fn,optimizer,epochs: int, device=device):\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    acc = []\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for X,Y in train_loader:\n",
    "            X,Y = X.to(device), Y.to(device)\n",
    "            output=model(X)\n",
    "            loss=loss_fn(output, Y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            for X,Y in val_loader:\n",
    "                X,Y = X.to(device), Y.to(device)\n",
    "                output=model(X)\n",
    "                loss=loss_fn(output, Y)\n",
    "                losses_test.append(loss.item())\n",
    "                y_pred = output.max(-1)[1]\n",
    "                acc.append((y_pred==Y).to(default_dtype).mean().item())\n",
    "        train_acc_task_3 = get_accuracy(model_task_1, train_data_loader)\n",
    "        test_acc_task_3 = get_accuracy(model_task_1, test_data_loader)\n",
    "        print(f'epoch {epoch+1}/{epochs}, {time.time()-start_time:.3f}s.')\n",
    "        print(f'\\t training loss: {losses_train[-1]:.6f}')\n",
    "        print(f'\\t validation loss: {losses_test[-1]:.6f}')\n",
    "        print(f'\\t val accuracy: {acc[-1]:.6f}')\n",
    "        print(f'\\t tr/tst diff: {train_acc_task_3-test_acc_task_3,train_acc_task_3,test_acc_task_3}')\n",
    "default_dtype = torch.float32      \n",
    "optimizer = torch.optim.SGD(model_task_1.parameters(), lr=0.008)\n",
    "epochs=6\n",
    "train_model(model_task_1, train_data_loader,test_data_loader,nn.CrossEntropyLoss(),optimizer,epochs,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.91133\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8921\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_fmnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_fmnist_data_dict.npy\"\n",
    "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_fmnist_task_1.json` в задачу Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
